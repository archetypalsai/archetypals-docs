---
title: "System Requirements"
description: "System Requirements to run Archetypal"
---

import { Callout } from "nextra/components";
import Image from "next/image";

<Image
  src="/images/getting-started/installation/system-requirements.png"
  height={1080}
  width={1920}
  quality={100}
  alt="Archetypal System Requirements"
/>

## System Requirements

Archetypal is fully customizable in every regard.

Given this customizable nature, your exact requirements to run Archetypal depend on many factors. You can use the tables below to get a rough idea of what it will take to run Archetypal.

Archetypal can be a wrapper around many external services that all accomplish some task - making Archetypal so lightweight it can run on the smallest machines - even Raspberry Pis!

## Recommended configuration for Archetypal

This is the minimum value for running Archetypal. This will be enough for you to store some documents, send chats, and use Archetypal features.

| Property | Recommended Value |
| -------- | ----------------- |
| RAM      | 2GB               |
| CPU      | 2-core CPU (any)  |
| Storage  | 5GB               |

## LLM selection impact

This is how you get chat responses. Popular hosted solutions like [OpenAI](https://openai.com/) tend to provide state-of-the-art responses with almost **zero overhead**. However, you will need an API key for any cloud-based LLM provider.

<Callout type="info" emoji="️💡">
  **Tip:** Host a local LLM on another machine that has a GPU if the device
  running Archetypal does not have a GPU. Archetypal can connect to any LLM
  running anywhere via API.
</Callout>

## Embedder selection impact

This is the model which you use to "**embed**" or vectorize text. Likewise, external services connected to Archetypal have **zero overhead** impact.

The default embedder runs on the same machine as Archetypal using **CPU-only** vectorization. If your documents are large or you need to vectorize a lot of data, you may want to use an external embedder provider and model.

## Vector database selection impact

All supported vector databases either have no impact as they are externally hosted or can scale to hundreds of millions of vectors at the minimum recommended settings.

_the default LanceDB vector database can handle anything you can throw at it_
